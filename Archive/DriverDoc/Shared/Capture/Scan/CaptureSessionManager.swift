//
//  CaptureManager.swift
//  MBDocCapture
//
//  Created by El Mahdi Boukhris on 16/04/2019.
//  Copyright Â© 2019 El Mahdi Boukhris <m.boukhris@gmail.com>
//
//  Permission is hereby granted, free of charge, to any person obtaining a copy
//  of this software and associated documentation files (the "Software"), to
//  deal in the Software without restriction, including without limitation the
//  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
//  sell copies of the Software, and to permit persons to whom the Software is
//  furnished to do so, subject to the following conditions:
//
//  The above copyright notice and this permission notice shall be included in
//  all copies or substantial portions of the Software.
//
//  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
//  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
//  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
//  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
//  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
//  DEALINGS IN THE SOFTWARE.
//

import Foundation
import CoreMotion
import CoreImage
import UIKit
import AVFoundation
//import Firebase
import Vision
/// A set of functions that inform the delegate object of the state of the detection.
protocol RectangleDetectionDelegateProtocol: NSObjectProtocol {
    
    /// Called when the capture of a picture has started.
    ///
    /// - Parameters:
    ///   - captureSessionManager: The `CaptureSessionManager` instance that started capturing a picture.
    func didStartCapturingPicture(for captureSessionManager: CaptureSessionManager)
    
    /// Called when a rectangle has been detected.
    /// - Parameters:
    ///   - captureSessionManager: The `CaptureSessionManager` instance that has detected a rectangle.
    ///   - rect: The detected rectangle in the coordinates of the image.
    ///   - imageSize: The size of the image the rectangle has been detected on.
    func captureSessionManager(_ captureSessionManager: CaptureSessionManager, didDetectRect rect: Rectangle?, _ imageSize: CGSize)
    
    /// Called when a picture with or without a rectangle has been captured.
    ///
    /// - Parameters:
    ///   - captureSessionManager: The `CaptureSessionManager` instance that has captured a picture.
    ///   - picture: The picture that has been captured.
    ///   - rect: The rectangle that was detected in the picture's coordinates if any.
    func captureSessionManager(_ captureSessionManager: CaptureSessionManager, didCapturePicture picture: UIImage, withRect rect: Rectangle?)
    
    /// Called when an error occured with the capture session manager.
    /// - Parameters:
    ///   - captureSessionManager: The `CaptureSessionManager` that encountered an error.
    ///   - error: The encountered error.
    func captureSessionManager(_ captureSessionManager: CaptureSessionManager, didFailWithError error: Error)
}

/// The CaptureSessionManager is responsible for setting up and managing the AVCaptureSession and the functions related to capturing.
final class CaptureSessionManager: NSObject, AVCaptureVideoDataOutputSampleBufferDelegate {
    
    private let videoPreviewLayer: AVCaptureVideoPreviewLayer
    private let captureSession = AVCaptureSession()
    private let rectangleFunnel = RectangleFeaturesFunnel()
    weak var delegate: RectangleDetectionDelegateProtocol?
    private var displayedRectangleResult: RectangleDetectorResult?
    private var photoOutput = AVCapturePhotoOutput()
    fileprivate var photoSettings = AVCapturePhotoSettings()
    /// Whether the CaptureSessionManager should be detecting rectangles.
    private var isDetecting = true
    
    /// The number of times no rectangles have been found in a row.
    private var noRectangleCount = 0
    
    /// The minimum number of time required by `noRectangleCount` to validate that no rectangles have been found.
    private let noRectangleThreshold = 3
    public var flashMode: AVCaptureDevice.FlashMode = .auto {
        didSet {
            let settings = AVCapturePhotoSettings()

            switch flashMode {
               case .auto: settings.flashMode = .auto
               case .on: settings.flashMode = .on
               default: settings.flashMode = .off
            }
            
            settings.flashMode = flashMode
            photoSettings = settings
        }
    }
    // MARK: Life Cycle
    
    init?(videoPreviewLayer: AVCaptureVideoPreviewLayer) {
        self.videoPreviewLayer = videoPreviewLayer
        super.init()
        
        guard let device = AVCaptureDevice.default(for: AVMediaType.video) else {
            let error = ImageScannerControllerError.inputDevice
            delegate?.captureSessionManager(self, didFailWithError: error)
            return nil
        }
        
        captureSession.beginConfiguration()
        captureSession.sessionPreset = AVCaptureSession.Preset.photo
        
        photoOutput.isHighResolutionCaptureEnabled = true
        
        let videoOutput = AVCaptureVideoDataOutput()
        videoOutput.alwaysDiscardsLateVideoFrames = true
        
        defer {
            device.unlockForConfiguration()
            captureSession.commitConfiguration()
        }
        guard let deviceInput = try? AVCaptureDeviceInput(device: device),
            captureSession.canAddInput(deviceInput),
            captureSession.canAddOutput(photoOutput),
            captureSession.canAddOutput(videoOutput) else {
                let error = ImageScannerControllerError.inputDevice
                delegate?.captureSessionManager(self, didFailWithError: error)
                return
        }
        
        do {
            try device.lockForConfiguration()
        } catch {
            let error = ImageScannerControllerError.inputDevice
            delegate?.captureSessionManager(self, didFailWithError: error)
            return
        }
        
        device.isSubjectAreaChangeMonitoringEnabled = true
        
        captureSession.addInput(deviceInput)
        captureSession.addOutput(photoOutput)
        captureSession.addOutput(videoOutput)
        videoPreviewLayer.session = captureSession
        videoPreviewLayer.videoGravity = .resizeAspectFill
        
        videoOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "video_ouput_queue"))
    }
    
    // MARK: Capture Session Life Cycle
    
    /// Starts the camera and detecting rectangles.
    internal func start() {
        let authorizationStatus = AVCaptureDevice.authorizationStatus(for: .video)
        
        switch authorizationStatus {
        case .authorized:
            DispatchQueue.main.async {
                self.captureSession.startRunning()
            }
            isDetecting = true
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: AVMediaType.video, completionHandler: { (_) in
                DispatchQueue.main.async { [weak self] in
                    self?.start()
                }
            })
        default:
            let error = ImageScannerControllerError.authorization
            delegate?.captureSessionManager(self, didFailWithError: error)
        }
    }
    
    internal func stop() {
        captureSession.stopRunning()
    }
    
    internal func capturePhoto() {
        guard let connection = photoOutput.connection(with: .video), connection.isEnabled, connection.isActive else {
            let error = ImageScannerControllerError.capture
            delegate?.captureSessionManager(self, didFailWithError: error)
            return
        }
        photoOutput.capturePhoto(with: getSettings(), delegate: self)
    }
    
    func getSettings() -> AVCapturePhotoSettings {
        let settings = AVCapturePhotoSettings()
        settings.isHighResolutionPhotoEnabled = true
        settings.isAutoStillImageStabilizationEnabled = true
        settings.flashMode = flashMode
        return settings
    }
    // MARK: - AVCaptureVideoDataOutputSampleBufferDelegate
    
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        guard isDetecting == true,
            let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
            return
        }

        let imageSize = CGSize(width: CVPixelBufferGetWidth(pixelBuffer), height: CVPixelBufferGetHeight(pixelBuffer))

        let finalImage = CIImage(cvPixelBuffer: pixelBuffer)
        CIRectangleDetector.rectangle(forImage: finalImage) { (rectangle) in
            self.processRectangle(rectangle: rectangle, imageSize: imageSize)
        }
//        if #available(iOS 11.0, *) {
//            let request  = VNDetectRectanglesRequest { [weak self](req, error) in
//                if let err = error {
//                    print("Failed to detect:", err)
//                    return
//                }
//
//                let rects = req.results?.compactMap({ (res) -> Rectangle? in
//
//                    guard let rectangleObservation = res as? VNRectangleObservation else { return nil }
//                    let transform = CGAffineTransform.identity
//                        .scaledBy(x: 1, y: -1)
//                        .translatedBy(x: 0, y: -(self?.videoPreviewLayer.frame.height ?? 0))
//                        .scaledBy(x: self?.videoPreviewLayer.frame.width ?? 0, y: self?.videoPreviewLayer.frame.height ?? 0)
//
//                    let convertedTopLeft = rectangleObservation.topLeft.applying(transform)
//                    let convertedTopRight = rectangleObservation.topRight.applying(transform)
//                    let convertedBottomLeft = rectangleObservation.bottomLeft.applying(transform)
//                    let convertedBottomRight = rectangleObservation.bottomRight.applying(transform)
//                    let rect = Rectangle(topLeft: convertedTopLeft, topRight: convertedTopRight, bottomRight: convertedBottomRight, bottomLeft: convertedBottomLeft)
//                    return rect
//
//                })
//                print(" detect xxx:", rects?.biggest())
//
//                self?.processRectangle(rectangle: rects?.biggest(), imageSize: imageSize)
//            }
//
//            request.maximumObservations = 8 // Vision currently supports up to 16.
//            request.minimumConfidence = 0.6 // Be confident.
//            request.minimumAspectRatio = 0.3 // height / width
//            DispatchQueue.global(qos: .userInitiated).async {
//                let handler = VNImageRequestHandler(ciImage: finalImage, options: [:])
//                do {
//                    try handler.perform([request])
//                    print(" detect xxx: ==== ")
//                } catch let reqErr {
//                    print("Failed to perform request:", reqErr)
//                }
//            }
//        } else {
//            // Fallback on earlier versions
//
//        }
//
    }
    
    private func processRectangle(rectangle: Rectangle?, imageSize: CGSize) {
        if let rectangle = rectangle {
            
            self.noRectangleCount = 0
            self.rectangleFunnel.add(rectangle, currentlyDisplayedRectangle: self.displayedRectangleResult?.rectangle) { [weak self] (result, rectangle) in
                
                guard let strongSelf = self else {
                    return
                }
                
                let shouldAutoScan = (result == .showAndAutoScan)
                strongSelf.displayRectangleResult(rectangleResult: RectangleDetectorResult(rectangle: rectangle, imageSize: imageSize))
                if shouldAutoScan, CaptureSession.current.isAutoScanEnabled, !CaptureSession.current.isEditing {
                    capturePhoto()
                }
            }
            
        } else {
            
            DispatchQueue.main.async { [weak self] in
                guard let strongSelf = self else {
                    return
                }
                strongSelf.noRectangleCount += 1
                
                if strongSelf.noRectangleCount > strongSelf.noRectangleThreshold {
                    // Reset the currentAutoScanPassCount, so the threshold is restarted the next time a rectangle is found
                    strongSelf.rectangleFunnel.currentAutoScanPassCount = 0
                    
                    // Remove the currently displayed rectangle as no rectangles are being found anymore
                    strongSelf.displayedRectangleResult = nil
                    strongSelf.delegate?.captureSessionManager(strongSelf, didDetectRect: nil, imageSize)
                }
            }
            return
            
        }
    }
    
    @discardableResult private func displayRectangleResult(rectangleResult: RectangleDetectorResult) -> Rectangle {
        displayedRectangleResult = rectangleResult
        
        let rect = rectangleResult.rectangle.toCartesian(withHeight: rectangleResult.imageSize.height)
        
        DispatchQueue.main.async { [weak self] in
            guard let strongSelf = self else {
                return
            }
            
            strongSelf.delegate?.captureSessionManager(strongSelf, didDetectRect: rect, rectangleResult.imageSize)
        }
        
        return rect
    }
}

extension CaptureSessionManager: AVCapturePhotoCaptureDelegate {
        
    func photoOutput(_ captureOutput: AVCapturePhotoOutput, didFinishProcessingPhoto photoSampleBuffer: CMSampleBuffer?, previewPhoto previewPhotoSampleBuffer: CMSampleBuffer?, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings?, error: Error?) {
        if let error = error {
            delegate?.captureSessionManager(self, didFailWithError: error)
            return
        }
        
        CaptureSession.current.setImageOrientation()
        
        isDetecting = false
        rectangleFunnel.currentAutoScanPassCount = 0
        delegate?.didStartCapturingPicture(for: self)
        
//        if let sampleBuffer = photoSampleBuffer,
//            let imageData = AVCapturePhotoOutput.jpegPhotoDataRepresentation(forJPEGSampleBuffer: sampleBuffer, previewPhotoSampleBuffer: nil) {
//            completeImageCapture(with: imageData)
//        } else {
//            let error = ImageScannerControllerError.capture
//            delegate?.captureSessionManager(self, didFailWithError: error)
//            return
//        }
        
    }
    
    @available(iOS 11.0, *)
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            delegate?.captureSessionManager(self, didFailWithError: error)
            return
        }
        
        CaptureSession.current.setImageOrientation()
        
        isDetecting = false
        rectangleFunnel.currentAutoScanPassCount = 0
        delegate?.didStartCapturingPicture(for: self)
        
        if let imageData = photo.fileDataRepresentation() {
            completeImageCapture(with: imageData)
        } else {
            let error = ImageScannerControllerError.capture
            delegate?.captureSessionManager(self, didFailWithError: error)
            return
        }
    }
    
    /// Completes the image capture by processing the image, and passing it to the delegate object.
    /// This function is necessary because the capture functions for iOS 10 and 11 are decoupled.
    private func completeImageCapture(with imageData: Data) {
        DispatchQueue.global(qos: .background).async { [weak self] in
            guard let strongSelf = self else {
                return
            }
            CaptureSession.current.isEditing = true
            guard let image = UIImage(data: imageData) else {
                let error = ImageScannerControllerError.capture
                DispatchQueue.main.async {
                    guard let strongSelf = self else {
                        return
                    }
                    strongSelf.delegate?.captureSessionManager(strongSelf, didFailWithError: error)
                }
                return
            }
            
            
            var angle: CGFloat = 0.0
//            image.withFixedOrientation()
            print(image.imageOrientation.rawValue)
            switch image.imageOrientation {
            case .right:
                angle = CGFloat.pi / 2
            case .up:
                angle = CGFloat.pi
            default:
                break
            }
            var rect: Rectangle?
            if let displayedRectangleResult = self?.displayedRectangleResult {
                rect = self?.displayRectangleResult(rectangleResult: displayedRectangleResult)
                rect = rect?.scale(displayedRectangleResult.imageSize, image.size, withRotationAngle: angle)
            }
            DispatchQueue.main.async {
                strongSelf.delegate?.captureSessionManager(strongSelf, didCapturePicture: image, withRect: rect)
            }
            
        }
    }
    
//    func imageOrientation(
//        deviceOrientation: UIDeviceOrientation,
//        cameraPosition: AVCaptureDevice.Position
//        ) -> VisionDetectorImageOrientation {
//        switch deviceOrientation {
//        case .portrait:
//            return cameraPosition == .front ? .leftTop : .rightTop
//        case .landscapeLeft:
//            return cameraPosition == .front ? .bottomLeft : .topLeft
//        case .portraitUpsideDown:
//            return cameraPosition == .front ? .rightBottom : .leftBottom
//        case .landscapeRight:
//            return cameraPosition == .front ? .topRight : .bottomRight
//        case .faceDown, .faceUp, .unknown:
//            return .leftTop
//        }
//    }
}

/// Data structure representing the result of the detection of a rectangle.
private struct RectangleDetectorResult {
    
    /// The detected rectangle.
    let rectangle: Rectangle
    
    /// The size of the image the rectangle was detected on.
    let imageSize: CGSize
    
}
